
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          REPO QUERY - FULL DATA FLOW                                     â•‘
â•‘                    (Gradio UI â†’ RAG Orchestrator â†’ Services)                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BROWSER / GRADIO UI                                                                     â”‚
â”‚  ingestion_service/src/ui/gradio_app.py                                                  â”‚
â”‚                                                                                           â”‚
â”‚  1a. demo.load() fires on page load          1b. User clicks "Refresh Repos"             â”‚
â”‚       â””â”€â”€ refresh_repos()                         â””â”€â”€ refresh_repos()                    â”‚
â”‚               â”‚                                                                           â”‚
â”‚               â””â”€â”€ GET http://ingestion_service:8001/v1/repos                             â”‚
â”‚                       â”‚                                                                   â”‚
â”‚                       â–¼                                                                   â”‚
â”‚               â† List[RepoSummary]                                                         â”‚
â”‚               â†’ populates repo_dropdown                                                   â”‚
â”‚                                                                                           â”‚
â”‚  2. User selects repo, enters query, clicks "Ask Graph RAG"                              â”‚
â”‚       â””â”€â”€ submit_rag_query(query, repo_id, top_k, provider, model)                       â”‚
â”‚               â”‚                                                                           â”‚
â”‚               â””â”€â”€ POST http://rag_orchestrator:8004/v1/rag                               â”‚
â”‚                       body: {query, repo_id, top_k, provider, model}                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG ORCHESTRATOR  :8004                                                                  â”‚
â”‚  rag_orchestrator/src/core/service.py  â†’  run_rag()                                      â”‚
â”‚                                                                                           â”‚
â”‚  STEP 1: RESOLVE REPO                                                                     â”‚
â”‚  resolve_repo_id_http(repo_id)                                                            â”‚
â”‚       â””â”€â”€ GET ingestion_service:8001/v1/repos                                             â”‚
â”‚               â”‚                                                                           â”‚
â”‚               â–¼  [ingestion_service]                                                      â”‚
â”‚               repos.py router â†’ db_utils.list_complete_repos()                            â”‚
â”‚               â†’ JOIN DocumentNode + IngestionRequest WHERE status='complete'              â”‚
â”‚               â†’ COUNT nodes, COUNT distinct files                                         â”‚
â”‚               â† List[RepoSummary]                                                         â”‚
â”‚               â”‚                                                                           â”‚
â”‚               â–¼  [back in rag_orchestrator]                                               â”‚
â”‚               validate repo_id exists & is complete                                       â”‚
â”‚               â†’ resolved_repo_id                                                          â”‚
â”‚                                                                                           â”‚
â”‚  STEP 2: EMBED QUERY                                                                      â”‚
â”‚  embed_query(query, embedder)                                                             â”‚
â”‚       â””â”€â”€ local embedder (Ollama or configured provider)                                  â”‚
â”‚               â† query_embedding: List[float]                                              â”‚
â”‚                                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  hybrid_retrieve()  [service.py]                                                          â”‚
â”‚                                                                                           â”‚
â”‚  STEP 3: VECTOR SEARCH                                                                    â”‚
â”‚       â””â”€â”€ POST vector_store:8003/v1/vectors/search                                        â”‚
â”‚               body: {query_vector, k, metadata_filter: {doc_type: "code"}}               â”‚
â”‚               (falls back without metadata_filter if no results)                          â”‚
â”‚               â† [{chunk_id, text, score, document_id, metadata:{canonical_id,...}}]      â”‚
â”‚               â†’ seed_chunks: List[RetrievedChunk]                                         â”‚
â”‚               â†’ seed_canonical_ids = extract_canonical_ids_from_chunks(seed_chunks)      â”‚
â”‚                    â””â”€â”€ reads chunk.metadata["canonical_id"] for each chunk               â”‚
â”‚                                                                                           â”‚
â”‚  STEP 4: LOAD / FETCH GRAPH  (if seed_canonical_ids not empty)                           â”‚
â”‚  get_cached_graph(repo_id)  [codebase_utils.py]                                           â”‚
â”‚       â”‚                                                                                   â”‚
â”‚       â”œâ”€â”€ HIT:  return _repo_graphs[repo_id]  (in-memory cache)                          â”‚
â”‚       â”‚                                                                                   â”‚
â”‚       â””â”€â”€ MISS: load_graph_for_repo(repo_id)  [codebase_queries.py]                      â”‚
â”‚                   â”‚                                                                        â”‚
â”‚                   â””â”€â”€ GET ingestion_service:8001/v1/graph/repos/{repo_id}                â”‚
â”‚                           â”‚                                                                â”‚
â”‚                           â–¼  [ingestion_service]                                          â”‚
â”‚                           graph.py router                                                 â”‚
â”‚                           â†’ db_utils.get_full_graph_for_repo(repo_id)                    â”‚
â”‚                               â”œâ”€â”€ SELECT * FROM document_nodes WHERE repo_id=?           â”‚
â”‚                               â””â”€â”€ SELECT * FROM document_relationships WHERE repo_id=?   â”‚
â”‚                           â† {                                                             â”‚
â”‚                               "nodes": {canonical_id â†’ node_dict},                       â”‚
â”‚                               "relationships": {from_cid â†’ [{to_cid, relation_type}]}    â”‚
â”‚                             }                                                             â”‚
â”‚                           â”‚                                                               â”‚
â”‚                           â–¼  [back in rag_orchestrator]                                   â”‚
â”‚                           build CodebaseGraph in memory:                                  â”‚
â”‚                           â”œâ”€â”€ for each node â†’ Node(canonical_id, file_path, lineno)      â”‚
â”‚                           â””â”€â”€ for each edge â†’ graph.add_edge(from, to, relation_type)    â”‚
â”‚                               sets Node.out_edges and Node.in_edges                       â”‚
â”‚                           â†’ cached in _repo_graphs[repo_id]                              â”‚
â”‚                                                                                           â”‚
â”‚  STEP 5: GRAPH TRAVERSAL                                                                  â”‚
â”‚  select_traversal_strategies(query, seed_canonical_ids)  [traversal_selector.py]         â”‚
â”‚       â””â”€â”€ keyword match on query:                                                         â”‚
â”‚               "method/function/class/in" â†’ [traverse_defines(depth=1)]                   â”‚
â”‚               "callers/called by"        â†’ [traverse_incoming_calls(depth=1)]             â”‚
â”‚               "calls/call"               â†’ [traverse_calls(depth=1)]                      â”‚
â”‚               "import"                   â†’ [traverse_incoming_imports(depth=1)]           â”‚
â”‚               default                    â†’ [traverse_defines, traverse_calls]             â”‚
â”‚                                                                                           â”‚
â”‚  execute_traversals(graph, start_cid, strategies)  [traversal_selector.py]               â”‚
â”‚       â””â”€â”€ for each strategy:                                                              â”‚
â”‚               bfs_traversal(graph, start_cid, ...)  [codebase_queries.py]                â”‚
â”‚               â”œâ”€â”€ traverse_calls()           CALL edges,   forward,  BFS                 â”‚
â”‚               â”œâ”€â”€ traverse_defines()         DEFINES edges,forward,  BFS                 â”‚
â”‚               â”œâ”€â”€ traverse_incoming_calls()  CALL edges,   reverse,  BFS                 â”‚
â”‚               â””â”€â”€ traverse_incoming_imports()IMPORT edges, reverse,  BFS                 â”‚
â”‚               â† List[Node]  (deduplicated by canonical_id)                               â”‚
â”‚               â†’ expanded_canonical_ids                                                    â”‚
â”‚                                                                                           â”‚
â”‚  STEP 6: RESOLVE ALL CANONICAL IDS â†’ DOCUMENT IDS                                        â”‚
â”‚  canonical_ids_to_document_ids_http(repo_id, seed_cids âˆª expanded_cids) [service.py]    â”‚
â”‚       â””â”€â”€ GET ingestion_service:8001/v1/graph/repos/{repo_id}/nodes                      â”‚
â”‚               params: canonical_ids=cid1,cid2,...                                         â”‚
â”‚               â”‚                                                                            â”‚
â”‚               â–¼  [ingestion_service]                                                       â”‚
â”‚               graph.py router                                                             â”‚
â”‚               â†’ db_utils.get_document_nodes_by_canonical_ids(repo_id, canonical_ids)     â”‚
â”‚               â†’ SELECT * FROM document_nodes                                              â”‚
â”‚                   WHERE repo_id=? AND canonical_id IN (...)                               â”‚
â”‚               â† [{document_id, canonical_id, ...}]                                        â”‚
â”‚               â”‚                                                                            â”‚
â”‚               â–¼  [back in rag_orchestrator]                                               â”‚
â”‚               â†’ all_document_ids: Set[str]                                                â”‚
â”‚               â†’ missing_doc_ids = all_document_ids - seed_doc_ids                        â”‚
â”‚                                                                                           â”‚
â”‚  STEP 7: FETCH CHUNKS FOR EXPANDED DOCS                                                   â”‚
â”‚       â””â”€â”€ for each doc_id in missing_doc_ids:                                             â”‚
â”‚               POST vector_store:8003/v1/vectors/search-by-doc                             â”‚
â”‚               body: {document_id, k=10}                                                   â”‚
â”‚               â† [{chunk_id, text, score}]                                                 â”‚
â”‚               â†’ appended to retrieved_chunks_by_document                                  â”‚
â”‚                                                                                           â”‚
â”‚               â† retrieved_chunks_by_document: Dict[doc_id â†’ List[RetrievedChunk]]        â”‚
â”‚               â† retrieval_plan_dict: {seed_cids, expanded_cids, doc counts}              â”‚
â”‚                                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACK IN run_rag()  [service.py]                                                          â”‚
â”‚                                                                                           â”‚
â”‚  STEP 8: PLAN + RANK CHUNKS                                                               â”‚
â”‚  execute_retrieval_plan(plan, retrieved_chunks_by_document)  [execute_plan.py]            â”‚
â”‚       â””â”€â”€ applies RetrievalPlan constraints, ordering, dedup                             â”‚
â”‚           â† ranked List[RetrievedChunk]                                                   â”‚
â”‚                                                                                           â”‚
â”‚  STEP 9: PREPARE FOR LLM                                                                  â”‚
â”‚  prepare_chunks_for_agent(...)  [agent_adapter.py]                                        â”‚
â”‚       â””â”€â”€ apply max_chunks_per_doc, filter_chunk fn, ordering                            â”‚
â”‚           â† agent_chunks: List[Dict]                                                      â”‚
â”‚                                                                                           â”‚
â”‚  STEP 10: TOKEN BUDGET                                                                    â”‚
â”‚       â””â”€â”€ walk agent_chunks, accumulate token count (word-based approximation)           â”‚
â”‚           stop when > max_total_tokens (default 4096)                                     â”‚
â”‚           â†’ context_str: str                                                              â”‚
â”‚                                                                                           â”‚
â”‚  STEP 11: LLM CALL                                                                        â”‚
â”‚       â””â”€â”€ POST llm_service/generate                                                       â”‚
â”‚               body: {context: context_str, query: query}                                  â”‚
â”‚               params: {provider, model}  (if provided)                                    â”‚
â”‚               â† {response: "...answer text..."}                                           â”‚
â”‚                                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESPONSE BACK TO GRADIO                                                                  â”‚
â”‚                                                                                           â”‚
â”‚  RAGResult {                                                                              â”‚
â”‚      answer:         str           â† from LLM                                             â”‚
â”‚      sources:        List[str]     â† document_ids of chunks used                         â”‚
â”‚      repo_id:        str                                                                  â”‚
â”‚      retrieval_plan: Dict {                                                               â”‚
â”‚          seed_canonical_ids,   expanded_canonical_ids,                                   â”‚
â”‚          seed_docs,            expanded_docs,           total_docs                        â”‚
â”‚      }                                                                                    â”‚
â”‚  }                                                                                        â”‚
â”‚                                                                                           â”‚
â”‚  submit_rag_query() formats into:                                                         â”‚
â”‚      "ğŸ¯ Repository: ...                                                                  â”‚
â”‚       Answer: ...                                                                         â”‚
â”‚       Sources: ..."                                                                       â”‚
â”‚  â†’ displayed in rag_output Textbox                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SERVICE MAP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  :8001  ingestion_service    /v1/repos
                              /v1/graph/repos/{id}            â† full graph load
                              /v1/graph/repos/{id}/nodes      â† canonicalâ†’doc_id lookup
                              /v1/graph/repos/{id}/relationships

  :8003  vector_store         /v1/vectors/search              â† semantic search
                              /v1/vectors/search-by-doc       â† fetch by doc_id

  :8004  rag_orchestrator     /v1/rag                         â† entry point

  llm_service                 /generate                       â† answer generation

  :7860  gradio_app           browser UI
